{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import re\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.linalg import logm\n",
    "from pyquaternion import Quaternion\n",
    "from typing import Tuple, List, Dict\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def quaternion_inverse(given_quat):\n",
    "    \"\"\"\n",
    "    Input: scipy format - scalar LAST. numpy.array([b, c, d, a]) where quaternion is a + bi + cj + dk\n",
    "    or in wxyz format, w is scalar below\n",
    "    Output: numpy array in same format but inverse of input\n",
    "    \"\"\"\n",
    "    #pyquaternion library: Scalar FIRST: numpy.array([a, b, c, d]) where quaternion is a + bi + cj + dk\n",
    "    qx, qy, qz, qw = given_quat #scalar last\n",
    "    given_quat_scalar_first = np.array([qw, qx, qy, qz]) #scalar first\n",
    "    quat_obj = Quaternion(array=given_quat_scalar_first) \n",
    "    inv_quat = quat_obj.inverse\n",
    "    inv_quat_np = inv_quat.elements\n",
    "\n",
    "    iqw, iqx, iqy, iqz  = inv_quat_np #scalar first\n",
    "    inv_quat_np_scalar_first = np.array([iqx, iqy, iqz, iqw]) #scalar  last\n",
    "    return  inv_quat_np_scalar_first\n",
    "\n",
    "\n",
    "def get_rotation_error_using_arccos_of_trace_of_rotation(R_pred: np.ndarray, R_gt: np.ndarray) -> float:\n",
    "    # See https://www.notion.so/saishubodh/Evaluation-Metrics-for-R-t-with-GT-Rotation-Translation-error-with-Ground-truth-476db686933048d5b74de36b382e0eec\n",
    "        # measure the angular distance between two rotation matrice\n",
    "    # R1,R2: [n, 3, 3]\n",
    "    # Returns angle in degrees\n",
    "    if R_pred.shape == (3,3):\n",
    "        R_pred = R_pred[np.newaxis,:]\n",
    "    if R_gt.shape == (3,3):\n",
    "        R_gt = R_gt[np.newaxis,:]\n",
    "    n = R_gt.shape[0]\n",
    "    trace_idx = [0,4,8]\n",
    "    trace = np.matmul(R_pred, R_gt.transpose(0,2,1)).reshape(n,-1)[:,trace_idx].sum(1)\n",
    "    metric_in_degrees = np.arccos(((trace - 1)/2).clip(-1,1)) / np.pi * 180.0\n",
    "    return metric_in_degrees[0]\n",
    "\n",
    "\n",
    "def get_rotation_error_using_quaternion_dot(R_pred: np.ndarray, R_gt: np.ndarray) -> float:\n",
    "    # See https://www.notion.so/saishubodh/Evaluation-Metrics-for-R-t-with-GT-Rotation-Translation-error-with-Ground-truth-476db686933048d5b74de36b382e0eec\n",
    "    # cpp\n",
    "    # const float d1 = std::fabs(q1.dot(q2));\n",
    "    #d2 = std::fmin(1.0f, std::fmax(-1.0f, d1))\n",
    "    #return 2 * acos(d2) * 180 / M_PI\n",
    "\n",
    "    # return np.linalg.norm(logm(np.matmul(R_pred, R_gt.transpose()))) / np.sqrt(2)\n",
    "    if R_pred.shape != (3, 3) or R_gt.shape != (3, 3):\n",
    "        raise ValueError(f'Input matrices must be 3x3, instead got {R_pred.shape} and {R_gt.shape}')\n",
    "\n",
    "    R_pred_obj, R_gt_obj = R.from_matrix(R_pred), R.from_matrix(R_gt)\n",
    "    quat_pred, quat_gt = R_pred_obj.as_quat(), R_gt_obj.as_quat()\n",
    "\n",
    "    # quat_pred_inv, quat_gt_inv = quaternion_inverse(quat_pred), quaternion_inverse(quat_gt)\n",
    "    # quat_pred_inv_i, quat_gt_inv_i = quaternion_inverse(quat_pred_inv), quaternion_inverse(quat_gt_inv)\n",
    "    # print(quat_pred, quat_gt)\n",
    "    # print(quat_pred_inv, quat_gt_inv)\n",
    "    # print(quat_pred_inv_i, quat_gt_inv_i)\n",
    "\n",
    "    # d1 = abs(np.dot(quat_pred, quat_gt))\n",
    "    # print(\"Quat inverse\")\n",
    "    d1 = abs(np.dot(quaternion_inverse(quat_pred), quat_gt))\n",
    "    d2 = np.min((1.0, np.max((-1.0, d1))))\n",
    "    rotation_error_in_degrees = 2 * np.arccos(d2) * 180 / np.pi\n",
    "    # print(rotation_error_in_degrees)\n",
    "    return rotation_error_in_degrees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_rotation_error_using_log_of_rotation(R_pred: np.ndarray, R_gt: np.ndarray) -> float:\n",
    "    # See https://www.notion.so/saishubodh/Evaluation-Metrics-for-R-t-with-GT-Rotation-Translation-error-with-Ground-truth-476db686933048d5b74de36b382e0eec\n",
    "    if R_pred.shape != (3, 3) or R_gt.shape != (3, 3):\n",
    "        raise ValueError(f'Input matrices must be 3x3, instead got {R_pred.shape} and {R_gt.shape}')\n",
    "\n",
    "    return np.linalg.norm(logm(np.matmul(R_pred, R_gt.transpose()))) / np.sqrt(2)\n",
    "\n",
    "def get_translation_error(t_pred: np.ndarray, t_gt: np.ndarray) -> float:\n",
    "    if t_gt.shape != (3, ) or t_gt.shape != (3, ):\n",
    "        raise ValueError(f'Input vectors must be 3 dimensional, instead got {t_pred.shape} and {t_gt.shape}')\n",
    "\n",
    "    return np.linalg.norm(t_gt - t_pred)\n",
    "\n",
    "def get_both_errors(T_pred: np.ndarray, T_gt: np.ndarray) -> Tuple[float, float]:\n",
    "    if T_pred.shape != (4, 4) or T_gt.shape != (4, 4):\n",
    "        raise ValueError(f'Input matrices must be 4x4, instead got {T_pred.shape} and {T_gt.shape}')\n",
    "\n",
    "    # rot_error = get_rotation_error_using_quaternion_dot(T_pred[:3, :3], T_gt[:3, :3])\n",
    "    # print(rot_error, \"quat\")\n",
    "    rot_error = get_rotation_error_using_log_of_rotation(T_pred[:3, :3], T_gt[:3, :3])\n",
    "    # print(rot_error, \"trace\")\n",
    "    trans_error = get_translation_error(T_pred[:3, -1], T_gt[:3, -1])\n",
    "    return (rot_error, trans_error)\n",
    "\n",
    "def get_errors(preds: List[np.ndarray], truths: List[np.ndarray]) -> Tuple[List[float], List[float]]:\n",
    "    if len(preds) != len(truths):\n",
    "        raise ValueError(f'Input must consist of equal numbers of predictions and ground truths, instead got {len(preds)} and {len(truths)}')\n",
    "    \n",
    "    rot_errors = []\n",
    "    trans_errors = []\n",
    "\n",
    "    for T_pred, T_gt in zip(preds, truths):\n",
    "        rot_err, trans_err = get_both_errors(T_pred, T_gt)\n",
    "        rot_errors.append(rot_err)\n",
    "        trans_errors.append(trans_err)\n",
    "\n",
    "    return rot_errors, trans_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_our_lp(file_path, freq):\n",
    "\twith open(file_path, \"r\") as f:\n",
    "\t\tcorr = f.readlines()\n",
    "\tcorr = [x.strip() for x in corr]\n",
    "\tcorr = sorted(corr, key=lambda x: float(x.split(\" \")[2]))\n",
    "\tnew_corr = []\n",
    "\tfor c in corr:\n",
    "\t\tc=c.strip()\n",
    "\t\t[l1, l2, s] = c.split()\n",
    "\t\tnew_corr.append([\n",
    "\t\t\tfreq*int(l1)+1,\n",
    "\t\t\tfreq*int(l2)+1,\n",
    "\t\t\tfloat(s)\n",
    "\t\t])\n",
    "\tprint(len(new_corr), len(new_corr))\n",
    "\treturn new_corr\n",
    "\n",
    "def read_rtabmap_lp(file_path):\n",
    "\twith open(file_path, \"r\") as f:\n",
    "\t\tcorr = f.readlines()\n",
    "\tnew_corr = []\n",
    "\tfor c in corr:\n",
    "\t\tc=c.strip()\n",
    "\t\t[l1, l2] = c.split()\n",
    "\t\tnew_corr.append([int(l1), int(l2)])\n",
    "\t\n",
    "\tprint(len(new_corr), len(new_corr))\n",
    "\treturn new_corr\n",
    "\n",
    "def read_poses(file_path):\n",
    "\twith open(file_path, \"r\") as f:\n",
    "\t\tposes = f.readlines()\n",
    "\tposes = [x.strip() for x in poses]\n",
    "\treturn poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 55\n",
      "32 32\n"
     ]
    }
   ],
   "source": [
    "Our_LP = read_our_lp(\"LP/ENV2/qsmall/our.txt\",3)\n",
    "Poses = read_poses(\"/home/ayushsharma/Documents/College/RRC/IROS2023/habitat-data/test/ENV2/qsmall/poses.csv\")\n",
    "Rtabmap_LP = read_rtabmap_lp(\"LP/ENV2/qsmall/rtabmap_qsmall_lp.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_err(Our_LP, Poses, flag=True):\n",
    "    ourLPErr = []\n",
    "    for lp in Our_LP:\n",
    "        if flag:\n",
    "            [l1, l2, _] = lp\n",
    "        else:\n",
    "            [l1, l2] = lp\n",
    "        p1 = Poses[l1].strip().split(',')\n",
    "        p2 = Poses[l2].strip().split(',')\n",
    "        q1 = [\n",
    "            float(p1[4]),\n",
    "            float(p1[5]),\n",
    "            float(p1[6]),\n",
    "            float(p1[7]),\n",
    "        ]\n",
    "        q2 = [\n",
    "            float(p2[4]),\n",
    "            float(p2[5]),\n",
    "            float(p2[6]),\n",
    "            float(p2[7]),\n",
    "        ]\n",
    "        r1 = R.from_quat(q1).as_matrix()\n",
    "        r2 = R.from_quat(q2).as_matrix()\n",
    "        # T1 = np.zeros((4,4))\n",
    "        # T2 = np.zeros((4,4))\n",
    "        # T1[:3,:3] = r1\n",
    "        # T2[:3,:3] = r2\n",
    "        # T1[:,3] = p1[1:4]\n",
    "        # T2[:,3] = p2[1:4]\n",
    "        ourLPErr.append(get_rotation_error_using_quaternion_dot(r1, r2))\n",
    "    return ourLPErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ourLPErr = get_err(Our_LP, Poses)\n",
    "rtabmapLPErr = get_err(Rtabmap_LP, Poses, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148, 157, 0.8006738424301147] 19.999999759894255\n",
      "[187, 754, 0.8018497228622437] 19.999964626492243\n",
      "[493, 661, 0.8019539713859558] 160.00003284860756\n",
      "[499, 667, 0.8025699257850647] 160.00003284860756\n",
      "[673, 685, 0.8033798336982727] 0.0\n",
      "[340, 334, 0.8042711019515991] 0.0\n",
      "[469, 790, 0.8050551414489746] 169.99996509256738\n",
      "[217, 211, 0.8053633570671082] 0.0\n",
      "[454, 457, 0.8055416345596313] 10.000001099841285\n",
      "[670, 679, 0.8068163394927979] 0.0\n",
      "[472, 790, 0.806876540184021] 169.99996509256738\n",
      "[499, 664, 0.8070405721664429] 160.00003284860756\n",
      "[496, 673, 0.807561457157135] 160.00003284860756\n",
      "[502, 661, 0.8078940510749817] 170.000031203606\n",
      "[751, 181, 0.8095076084136963] 19.999964626492243\n",
      "[490, 487, 0.8095747828483582] 19.99999858932556\n",
      "[499, 673, 0.8106867074966431] 160.00003284860756\n",
      "[466, 778, 0.8111031651496887] 169.99996509256738\n",
      "[496, 664, 0.8118925094604492] 160.00003284860756\n",
      "[145, 157, 0.8121135234832764] 19.999999759894255\n",
      "[496, 667, 0.812843918800354] 160.00003284860756\n",
      "[493, 664, 0.814326286315918] 160.00003284860756\n",
      "[664, 676, 0.8145216107368469] 0.0\n",
      "[472, 478, 0.8147596716880798] 0.0\n",
      "[673, 682, 0.8147913217544556] 0.0\n",
      "[154, 160, 0.8160078525543213] 10.00000026903258\n",
      "[505, 664, 0.8167425394058228] 170.000031203606\n",
      "[505, 667, 0.8181155323982239] 170.000031203606\n",
      "[151, 160, 0.8183306455612183] 19.999999759894255\n",
      "[469, 784, 0.8196761608123779] 169.99996509256738\n",
      "[337, 334, 0.8220613598823547] 0.0\n",
      "[502, 673, 0.8239427804946899] 170.000031203606\n",
      "[502, 664, 0.8242875337600708] 170.000031203606\n",
      "[151, 157, 0.8248612284660339] 19.999999759894255\n",
      "[502, 667, 0.8248909711837769] 170.000031203606\n",
      "[154, 157, 0.825690746307373] 10.00000026903258\n",
      "[499, 670, 0.8260143995285034] 160.00003284860756\n",
      "[673, 679, 0.8264042735099792] 0.0\n",
      "[217, 214, 0.8264560103416443] 0.0\n",
      "[505, 673, 0.8266598582267761] 170.000031203606\n",
      "[472, 784, 0.8308445811271667] 169.99996509256738\n",
      "[505, 670, 0.8340257406234741] 170.000031203606\n",
      "[496, 670, 0.8350797295570374] 160.00003284860756\n",
      "[751, 754, 0.8353691101074219] 0.0\n",
      "[475, 478, 0.8381207585334778] 0.0\n",
      "[502, 670, 0.8445669412612915] 170.000031203606\n",
      "[790, 793, 0.847000241279602] 0.0\n",
      "[670, 676, 0.8471232056617737] 0.0\n",
      "[703, 706, 0.8498772382736206] 19.9999991026362\n",
      "[379, 382, 0.8522405624389648] 1.7075472925031877e-06\n",
      "[280, 283, 0.8655956983566284] 19.999997223631276\n",
      "[547, 550, 0.8755829930305481] 0.0\n",
      "[673, 676, 0.8785402774810791] 0.0\n",
      "[409, 406, 0.901927649974823] 0.0\n",
      "[178, 175, 0.903142511844635] 0.0\n",
      "rtabmap\n",
      "[69, 52] 9.999998959727618\n",
      "[71, 51] 19.99999700494789\n",
      "[73, 51] 3.4150945850063755e-06\n",
      "[75, 50] 10.000008014737679\n",
      "[122, 76] 39.999996207509454\n",
      "[130, 74] 49.999987219358054\n",
      "[132, 75] 49.99999050230246\n",
      "[136, 121] 19.999996062613686\n",
      "[138, 122] 19.999996062613686\n",
      "[140, 122] 29.99999481260141\n",
      "[222, 206] 29.999997181317752\n",
      "[224, 208] 29.999997181317752\n",
      "[226, 210] 9.999998908310609\n",
      "[329, 313] 19.99999828030396\n",
      "[331, 315] 9.999999454727154\n",
      "[333, 315] 9.999999454727154\n",
      "[335, 314] 19.99999828030396\n",
      "[422, 404] 59.999993636080255\n",
      "[510, 492] 9.999998354998507\n",
      "[512, 492] 9.999998354998507\n",
      "[514, 492] 9.999998354998507\n",
      "[516, 492] 19.999997033469995\n",
      "[593, 571] 29.999990759573336\n",
      "[595, 571] 49.999989226867456\n",
      "[752, 184] 19.999964626492243\n",
      "[754, 186] 19.999964626492243\n",
      "[816, 801] 20.000000458596386\n",
      "[818, 801] 20.000000458596386\n",
      "[820, 804] 20.000000458596386\n",
      "[822, 801] 0.0\n",
      "[824, 800] 9.999999446045814\n",
      "[826, 800] 9.999999446045814\n"
     ]
    }
   ],
   "source": [
    "for id,e in enumerate(ourLPErr):\n",
    "    print(Our_LP[id], e)\n",
    "print(\"rtabmap\")\n",
    "for id,e in enumerate(rtabmapLPErr):\n",
    "    print(Rtabmap_LP[id], e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_statistics(data: List[Dict]) -> None:\n",
    "    table = []\n",
    "    for dataset in data:\n",
    "        res = {\n",
    "            'Dataset': dataset['name']+\":mean\",\n",
    "            'Rot. Error': np.mean(dataset['rot_errors']),\n",
    "            'Trans. Error': np.mean(dataset['trans_errors']),\n",
    "        }\n",
    "        table.append(res)\n",
    "        res = {\n",
    "            'Dataset': dataset['name']+\":max\",\n",
    "            'Rot. Error': np.max(dataset['rot_errors']),\n",
    "            'Trans. Error': np.max(dataset['trans_errors']),\n",
    "        }\n",
    "        table.append(res)\n",
    "        res = {\n",
    "            'Dataset': dataset['name']+\":min\",\n",
    "            'Rot. Error': np.min(dataset['rot_errors']),\n",
    "            'Trans. Error': np.min(dataset['trans_errors']),\n",
    "        }\n",
    "        table.append(res)\n",
    "\n",
    "    # print results\n",
    "    print(tabulate(table, headers='keys', tablefmt='presto'))\n",
    "\n",
    "    # histogram\n",
    "    fig, axs = plt.subplots(len(data), 2)\n",
    "    axs = axs.reshape((len(data), 2)) # when len(data) = 1\n",
    "    for i in range(len(data)):\n",
    "        r = data[i]['rot_errors']\n",
    "        t = data[i]['trans_errors']\n",
    "        axs[i, 0].hist(r, weights=np.ones(len(r))/len(r))\n",
    "        axs[i, 0].set_title(data[i]['name'])\n",
    "        axs[i, 0].set(xlabel='Rot. Error', ylabel='Fraction')\n",
    "\n",
    "        axs[i, 1].hist(t, weights=np.ones(len(t))/len(t))\n",
    "        axs[i, 1].set_title(data[i]['name'])\n",
    "        axs[i, 1].set(xlabel='Trans. Error', ylabel='Fraction')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PLOTTING THE RETRIEVAL')\n",
    "parser.add_argument('--root_dir', type=str, default='', help='Path to dataset')\n",
    "parser.add_argument('--dataset', type=str, default='berlin', \n",
    "        help='Dataset to use', choices=['spair_90', 'spair_180','SMALL','TOPVIEW','PERSPECTIVE','sT4fr6TAbpF','oxford', 'nordland', 'berlin'])\n",
    "parser.add_argument('--netvlad_predictions', type=str, default='', help='Path to NetVLAD Predictions')\n",
    "parser.add_argument('--reference_poses', type=str, default='', help='Path to reference_poses that needs to be filtered')\n",
    "parser.add_argument('--query_poses', type=str, default='', help='Path to query_poses that needs to be filtered')\n",
    "parser.add_argument('--rord_trans', type=str, default='', help='Path to predicted transformation computed using RoRD')\n",
    "parser.add_argument('--name', type=str, default='', help='Name to plot')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    opt = parser.parse_args()\n",
    "    dataset = get_whole_val_set(opt.root_dir, opt.dataset.lower())\n",
    "\n",
    "    db_lst = dataset.dbStruct.dbImage\n",
    "    db_lst = np.array([int(re.search('\\d+', x.replace(' ',''))[0]) for x in db_lst])\n",
    "    q_lst = dataset.dbStruct.qImage\n",
    "    q_lst = np.array([int(re.search('\\d+', x.replace(' ',''))[0]) for x in q_lst])\n",
    "    db_cood_lst = dataset.dbStruct.locDb\n",
    "    q_cood_lst = dataset.dbStruct.locQ\n",
    "    X_Db, Y_Db = db_cood_lst[:,0], db_cood_lst[:,1]\n",
    "    X_Q, Y_Q = q_cood_lst[:,0], q_cood_lst[:,1]\n",
    "\n",
    "    # since we didn't included Rot. in mat files that's why we need to do this.\n",
    "\n",
    "    df = pd.read_csv(opt.reference_poses)\n",
    "    col = df.columns\n",
    "    db_lst = np.array(db_lst)-1\n",
    "    [ db_qw, db_qx, db_qz, db_qy] = [df[col[4]][db_lst], df[col[5]][db_lst], df[col[6]][db_lst], df[col[7]][db_lst]]\n",
    "    quat_Db = np.vstack((db_qx, db_qy,db_qz, db_qw)).T\n",
    "    Rot_Db = R.from_quat(quat_Db).as_matrix()\n",
    "    Transform_Db = np.zeros((Rot_Db.shape[0],4,4))\n",
    "    Transform_Db[:,:3,:3] = Rot_Db\n",
    "    Transform_Db[:,0,3] = X_Db\n",
    "    Transform_Db[:,1,3] = Y_Db\n",
    "    Transform_Db[:,3,3] = np.ones(Rot_Db.shape[0])\n",
    "\n",
    "    df = pd.read_csv(opt.query_poses)\n",
    "    col = df.columns\n",
    "    q_lst = np.array(q_lst)-1\n",
    "    [ q_qw, q_qx, q_qz, q_qy] = [df[col[4]][q_lst], df[col[5]][q_lst], df[col[6]][q_lst], df[col[7]][q_lst]]\n",
    "    quat_Q = np.vstack((q_qx, q_qy,q_qz, q_qw)).T\n",
    "    Rot_Q = R.from_quat(quat_Q).as_matrix()\n",
    "    Transform_Q = np.zeros((Rot_Q.shape[0],4,4))\n",
    "    Transform_Q[:,:3,:3] = Rot_Q\n",
    "    Transform_Q[:,0,3] = X_Q\n",
    "    Transform_Q[:,1,3] = Y_Q\n",
    "    Transform_Q[:,3,3] = np.ones(Rot_Q.shape[0])\n",
    "\n",
    "\n",
    "    data = []\n",
    "    preds = []\n",
    "    truths = []\n",
    "\n",
    "    netvlad_candidates = np.load(opt.netvlad_predictions)\n",
    "    for i in range(netvlad_candidates.shape[0]):\n",
    "        for j in range(1):\n",
    "            u = np.argwhere(q_lst==q_lst[i])[0][0]\n",
    "            v = np.argwhere(db_lst==db_lst[int(netvlad_candidates[i,j])])[0][0]\n",
    "            R_gt = np.linalg.inv(Transform_Q[u]) @ Transform_Db[v]\n",
    "            R_pred = np.load(os.path.join(opt.rord_trans,str(q_lst[i]+1)+\"-\"+str(1+db_lst[int(netvlad_candidates[i,j])])+\".npy\"))\n",
    "            R_pred[2,3] = 0\n",
    "            truths.append(R_gt) \n",
    "            preds.append(R_pred) \n",
    "            if(i==0):\n",
    "                print(R_gt,  \"\\n\\n\\n\")\n",
    "                print(R_pred)\n",
    "\n",
    "    rot_errors, trans_errors = get_errors(preds, truths)\n",
    "    data.append({\n",
    "        'name': 'Query-Retrieved ('+ opt.name + \")\",\n",
    "        'rot_errors': rot_errors,\n",
    "        'trans_errors': trans_errors,\n",
    "    })\n",
    "    print_statistics(data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transformation_matrix_from_7(x1, y1, z1, qx1, qy1, qz1, qw1):\n",
    "\tr1 = R.from_quat([qx1, qy1, qz1, qw1])\n",
    "\tm1 = np.hstack((r1.as_matrix(), np.array([x1,y1,z1], dtype=np.float64).reshape(3,1)))\n",
    "\tm1 = np.vstack((m1, np.array([0,0,0,1], dtype=np.float64).reshape(1,4)))\n",
    "\treturn m1\n",
    "\n",
    "def quat2eulers(qw,qx,qy, qz):\n",
    "\t\n",
    "\tr = R.from_quat([qx, qy, qz, qw])\n",
    "\troll, pitch, yaw = r.as_euler('xyz', degrees=True)\n",
    "\treturn roll, pitch, yaw\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"LP/ENV2/qsmall/our.txt\", \"r\") as f:\n",
    "\tcorr = f.readlines()\n",
    "corr = [x.strip() for x in corr]\n",
    "corr = sorted(corr, key=lambda x: float(x.split(\" \")[2]))\n",
    "corr = corr[-32:]\n",
    "print(len(corr))\n",
    "\n",
    "with open(\"/home/ayushsharma/Documents/College/RRC/IROS2023/habitat-data/test/ENV2/qsmall/poses.csv\", \"r\") as f:\n",
    "\tposes = f.readlines()\n",
    "poses = [x.strip() for x in poses]\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in corr[-32:]:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pitchlist = []\n",
    "translationlist = []\n",
    "skipped = 0\n",
    "print(\"l1,l2,r,p,y,d\")\n",
    "for line in corr:\n",
    "\tl1 = int(line.split(\" \")[0])\n",
    "\tl2 = int(line.split(\" \")[1])\n",
    "\t_ , x1, y1, z1, qw1, qx1, qy1, qz1 = poses[3*l1 + 1].split(\",\")\n",
    "\t_ , x2, y2, z2, qw2, qx2, qy2, qz2 = poses[3*l2 + 1].split(\",\")\n",
    "\tr1, p1, yaw1 = quat2eulers(float(qw1), float(qx1), float(qy1), float(qz1))\n",
    "\tr2, p2, yaw2 = quat2eulers(float(qw2), float(qx2), float(qy2), float(qz2))\n",
    "\tx1 = float(x1)\n",
    "\tx2 = float(x2)\n",
    "\ty1 = float(y1)\n",
    "\ty2 = float(y2)\n",
    "\tz1 = float(z1)\n",
    "\tz2 = float(z2)\n",
    "\t# print(x1, x2, y1, y`2, z1, z2)\n",
    "\t# print(f\"{l1},{l2},{r1-r2},{p1-p2},{y1-y2},{math.sqrt((x1 - x2)**2 + (y1 - y2)**2 + (z1 - z2)**2)}\")\n",
    "\tdelta_translation = math.sqrt((x1 - x2)**2 + (y1 - y2)**2 + (z1 - z2)**2)\n",
    "\tif(delta_translation > 3):\n",
    "\t\t# print(f\"skipped {l1} {l2} because of large translation difference {delta_translation}\")\n",
    "\t\t# skipped +=1\n",
    "\t\tprint(\"dt \",3*l1+1, 3*l2+1, delta_translation, (r1,r2), (p1,p2), (yaw1,yaw2))\n",
    "\tpitchlist.append(abs(p1-p2))\n",
    "\tif abs(p1-p2)>60:\n",
    "\t\tprint(3*l1+1, 3*l2+1, p1, p2)\n",
    "\ttranslationlist.append(math.sqrt((x1 - x2)**2 + (y1 - y2)**2 + (z1 - z2)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-0.41388404\t0.056315005\t-13.540111\t0.996192574501038\t0\t0.0871804431080818\t0\n",
    "-0.6029608\t0.056315005\t-16.773697\t2.50637531280518E-05\t0\t-1\t0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10,5))\n",
    "fig, ax = plt.subplots(2,2, figsize=(10,10))\n",
    "\n",
    "ax[0,0].hist(pitchlist, bins=range(0,181, 10), density=True)\n",
    "ax[0,0].set_title(\"angle difference, ours \")\n",
    "# plt.show()\n",
    "ax[0, 1].hist(translationlist, bins=range(0,21,2), density=True)\n",
    "ax[0, 1].set_title(\"translation difference, ours\")\n",
    "\n",
    "with open(\"LP/ENV2/qsmall/rtabmap_qsmall_lp.txt\", \"r\") as f:\n",
    "\tcorr = f.readlines()\n",
    "corr = [x.strip() for x in corr]\n",
    "for t in corr:\n",
    "\tprint(t)\n",
    "\n",
    "pitchlist = []\n",
    "translationlist = []\n",
    "skipped = 0\n",
    "print(\"l1,l2,r,p,y,d\")\n",
    "for line in corr:\n",
    "\tl1 = int(line.split(\" \")[0])\n",
    "\tl2 = int(line.split(\" \")[1])\n",
    "\t_ , x1, y1, z1, qw1, qx1, qy1, qz1 = poses[l1].split(\",\")\n",
    "\t_ , x2, y2, z2, qw2, qx2, qy2, qz2 = poses[l2].split(\",\")\n",
    "\tr1, p1, yaw1 = quat2eulers(float(qw1), float(qx1), float(qy1), float(qz1))\n",
    "\tr2, p2, yaw2 = quat2eulers(float(qw2), float(qx2), float(qy2), float(qz2))\n",
    "\tx1 = float(x1)\n",
    "\tx2 = float(x2)\n",
    "\ty1 = float(y1)\n",
    "\ty2 = float(y2)\n",
    "\tz1 = float(z1)\n",
    "\tz2 = float(z2)\n",
    "\t# print(x1, x2, y1, y`2, z1, z2)\n",
    "\t# print(f\"{l1},{l2},{r1-r2},{p1-p2},{y1-y2},{math.sqrt((x1 - x2)**2 + (y1 - y2)**2 + (z1 - z2)**2)}\")\n",
    "\tdelta_translation = math.sqrt((x1 - x2)**2 + (y1 - y2)**2 + (z1 - z2)**2)\n",
    "\t# if(delta_translation > 5):\n",
    "\t# \tprint(f\"skipped {l1} {l2} because of large translation difference {x1} {x2} {y1} {y2} {z1} {z2}\")\n",
    "\t# \tskipped +=1\n",
    "\t# \tcontinue\n",
    "\tpitchlist.append(abs(p1-p2))\n",
    "\ttranslationlist.append(math.sqrt((x1 - x2)**2 + (y1 - y2)**2 + (z1 - z2)**2))\n",
    "ax[1,0].hist(pitchlist, bins=range(0,181,10), density=True)\n",
    "ax[1,0].set_title(\"angle difference, rtabmap\")\n",
    "# plt.show()\n",
    "ax[1, 1].hist(translationlist, bins=range(0,21,2), density=True)\n",
    "ax[1, 1].set_title(\"translation difference, rtabmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
